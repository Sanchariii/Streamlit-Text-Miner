{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from src.cleanText import cleanText\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, SpatialDropout1D\n",
    "\n",
    "\n",
    "def preprocess_data(data_path : str) -> dict:\n",
    "    \"\"\"\n",
    "    Preprocesses the data by cleaning the text and encoding the labels. \n",
    "\n",
    "    Args:\n",
    "        data_path (str): Path to the data folder\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with the processed data\n",
    "    \"\"\"\n",
    "    processed_data = {} \n",
    "    files = os.listdir(data_path)\n",
    "\n",
    "    for file in files:\n",
    "        if \"Hate\" in file:\n",
    "            df = pd.read_csv(os.path.join(data_path, file))\n",
    "            df = df.drop(columns=['Unnamed: 0', 'count', 'hate_speech', 'offensive_language', 'neither'], axis=1)\n",
    "            df = df.rename(columns={'tweet': 'text', 'class': 'label'})\n",
    "            df[\"text\"] = df[\"text\"].apply(lambda text: cleanText(re.sub(r\"RT @\\w+:\", \"\", text)))\n",
    "            le = LabelEncoder()\n",
    "            df['label'] = le.fit_transform(df['label'])\n",
    "        elif \"Sarcasm\" in file:\n",
    "            df = pd.read_csv(os.path.join(data_path, file))\n",
    "            df = df.rename(columns={'Tweet': 'text', 'Label': 'label'})\n",
    "            df['text'] = df['text'].apply(cleanText) \n",
    "            df['text'] = df['text'].apply(lambda text: cleanText(re.sub(r\"user \", \" \", text)))\n",
    "            le = LabelEncoder()\n",
    "            df['label'] = le.fit_transform(df['label'])\n",
    "        elif \"Stress\" in file:\n",
    "            df = pd.read_csv(os.path.join(data_path, file))\n",
    "            df = df.drop(columns=['subreddit', 'post_id', 'sentence_range', 'syntax_fk_grade', 'Stress Level'], axis=1)\n",
    "            df = df.rename(columns={'text': 'text', 'label': 'label'})\n",
    "            df['text'] = df['text'].apply(cleanText)\n",
    "            le = LabelEncoder()\n",
    "            df['label'] = le.fit_transform(df['label'])\n",
    "        elif \"Spam\" in file:\n",
    "            df = pd.read_csv(os.path.join(data_path, file))\n",
    "            df = df.rename(columns={'v2': 'text', 'v1': 'label'})\n",
    "            df['text'] = df['text'].apply(cleanText)\n",
    "            le = LabelEncoder()\n",
    "            df['label'] = le.fit_transform(df['label'])\n",
    "        elif \"Sentiment\" in file:\n",
    "            df = pd.read_csv(os.path.join(data_path, file))\n",
    "            df['text'] = df['text'].apply(cleanText)\n",
    "            le = LabelEncoder()\n",
    "            df['label'] = le.fit_transform(df['label'])\n",
    "        processed_data[file] = df  \n",
    "\n",
    "    return processed_data  \n",
    "\n",
    "data_path = \"../data\"\n",
    "processed_data = preprocess_data(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(\n",
    "            data : object, \n",
    "            num_classes=2 : int,\n",
    "            ) -> tuple:\n",
    "    \"\"\"\n",
    "    Prepares the data for training and testing.\n",
    "\n",
    "    Args:\n",
    "        data (object): The data to prepare.\n",
    "        num_classes (int, optional): The number of classes. Defaults to 2.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The training and testing data and labels.\n",
    "    \"\"\"\n",
    "    tokenizer = Tokenizer(num_words=10000, split=' ')\n",
    "    tokenizer.fit_on_texts(data['text'].values)\n",
    "    X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "    X = pad_sequences(X, maxlen=100)\n",
    "    \n",
    "    if num_classes == 2:\n",
    "        y = data['label'].values\n",
    "    else:\n",
    "        y = pd.get_dummies(data['label']).values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def model_architecture(\n",
    "                num_classes : int,\n",
    "                max_features=10000 : int,\n",
    "                embedding_dim=128 : int,\n",
    "                lstm_units=128 : int,\n",
    "                dropout_rate=0.2 : float,\n",
    "                ) -> object:\n",
    "    \"\"\"\n",
    "    Creates the model architecture.\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): The number of classes.\n",
    "        max_features (int, optional): The maximum number of features. Defaults to 10000.\n",
    "        embedding_dim (int, optional): The embedding dimension. Defaults to 128.\n",
    "        lstm_units (int, optional): The LSTM units. Defaults to 128.\n",
    "        dropout_rate (float, optional): The dropout rate. Defaults to 0.2.\n",
    "\n",
    "    Returns:\n",
    "        object: The model architecture.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, embedding_dim, input_length=100))\n",
    "    model.add(SpatialDropout1D(dropout_rate))  \n",
    "    model.add(Bidirectional(LSTM(lstm_units, return_sequences=True, dropout=dropout_rate, recurrent_dropout=dropout_rate)))\n",
    "    model.add(LSTM(lstm_units, dropout=dropout_rate, recurrent_dropout=dropout_rate))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    \n",
    "    if num_classes == 2:\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    else:\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(\n",
    "            model : object,\n",
    "            X_train : list,\n",
    "            X_test : list, \n",
    "            y_train : list,\n",
    "            y_test : list,\n",
    "            filename : str,\n",
    "            ) -> None:\n",
    "    \"\"\"\n",
    "    Trains the model and saves it to the models folder, and prints the accuracy on the test set.\n",
    "\n",
    "    Args:\n",
    "        model (object): The model to train.\n",
    "        X_train (list): The training data.\n",
    "        X_test (list): The test data.\n",
    "        y_train (list): The training labels.\n",
    "        y_test (list): The test labels.\n",
    "        filename (str): The name of the model.\n",
    "\n",
    "    Returns:\n",
    "        None    \n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.1)\n",
    "    model.save(f\"../models/{filename}.h5\")\n",
    "    model.evaluate(X_test, y_test)\n",
    "    print(\"Final accuracy on test set for \" + filename + \": \" + str(model.evaluate(X_test, y_test)[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "113/113 [==============================] - 58s 450ms/step - loss: 0.6149 - accuracy: 0.6544 - val_loss: 0.4761 - val_accuracy: 0.7775\n",
      "Epoch 2/5\n",
      "113/113 [==============================] - 55s 490ms/step - loss: 0.3052 - accuracy: 0.8767 - val_loss: 0.3816 - val_accuracy: 0.8350\n",
      "Epoch 3/5\n",
      "113/113 [==============================] - 52s 458ms/step - loss: 0.1536 - accuracy: 0.9497 - val_loss: 0.4587 - val_accuracy: 0.8200\n",
      "Epoch 4/5\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.0657 - accuracy: 0.9769 - val_loss: 0.5964 - val_accuracy: 0.8000\n",
      "Epoch 5/5\n",
      "113/113 [==============================] - 50s 442ms/step - loss: 0.0322 - accuracy: 0.9883 - val_loss: 0.8195 - val_accuracy: 0.8075\n",
      "32/32 [==============================] - 2s 73ms/step - loss: 0.9878 - accuracy: 0.7770\n",
      "32/32 [==============================] - 3s 82ms/step - loss: 0.9878 - accuracy: 0.7770\n",
      "Final accuracy on test set for Sentiment Analysis: 0.7770000100135803\n",
      "Epoch 1/5\n",
      "103/103 [==============================] - 56s 476ms/step - loss: 0.3982 - accuracy: 0.8413 - val_loss: 0.2042 - val_accuracy: 0.9288\n",
      "Epoch 2/5\n",
      "103/103 [==============================] - 47s 457ms/step - loss: 0.1652 - accuracy: 0.9417 - val_loss: 0.1950 - val_accuracy: 0.9397\n",
      "Epoch 3/5\n",
      "103/103 [==============================] - 45s 438ms/step - loss: 0.0816 - accuracy: 0.9731 - val_loss: 0.2575 - val_accuracy: 0.9123\n",
      "Epoch 4/5\n",
      "103/103 [==============================] - 46s 442ms/step - loss: 0.0398 - accuracy: 0.9881 - val_loss: 0.2678 - val_accuracy: 0.9205\n",
      "Epoch 5/5\n",
      "103/103 [==============================] - 46s 448ms/step - loss: 0.0253 - accuracy: 0.9902 - val_loss: 0.2891 - val_accuracy: 0.9096\n",
      "29/29 [==============================] - 2s 67ms/step - loss: 0.2968 - accuracy: 0.9199\n",
      "29/29 [==============================] - 2s 68ms/step - loss: 0.2968 - accuracy: 0.9199\n",
      "Final accuracy on test set for Sarcasm Detection: 0.9198682904243469\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 36s 434ms/step - loss: 0.6478 - accuracy: 0.6368 - val_loss: 0.6348 - val_accuracy: 0.6211\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 28s 434ms/step - loss: 0.3893 - accuracy: 0.8302 - val_loss: 0.6912 - val_accuracy: 0.6740\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 27s 426ms/step - loss: 0.2082 - accuracy: 0.9251 - val_loss: 0.8495 - val_accuracy: 0.6608\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 30s 466ms/step - loss: 0.0942 - accuracy: 0.9682 - val_loss: 1.1084 - val_accuracy: 0.6388\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 27s 424ms/step - loss: 0.0511 - accuracy: 0.9858 - val_loss: 1.2516 - val_accuracy: 0.6740\n",
      "18/18 [==============================] - 1s 74ms/step - loss: 1.0769 - accuracy: 0.7183\n",
      "18/18 [==============================] - 1s 67ms/step - loss: 1.0769 - accuracy: 0.7183\n",
      "Final accuracy on test set for Stress Detection: 0.7183098793029785\n",
      "Epoch 1/5\n",
      "558/558 [==============================] - 271s 476ms/step - loss: 0.4061 - accuracy: 0.8609 - val_loss: 0.2833 - val_accuracy: 0.9097\n",
      "Epoch 2/5\n",
      "558/558 [==============================] - 280s 501ms/step - loss: 0.2422 - accuracy: 0.9176 - val_loss: 0.2731 - val_accuracy: 0.9112\n",
      "Epoch 3/5\n",
      "558/558 [==============================] - 257s 461ms/step - loss: 0.1757 - accuracy: 0.9417 - val_loss: 0.3215 - val_accuracy: 0.9002\n",
      "Epoch 4/5\n",
      "558/558 [==============================] - 255s 457ms/step - loss: 0.1357 - accuracy: 0.9543 - val_loss: 0.3844 - val_accuracy: 0.8886\n",
      "Epoch 5/5\n",
      "558/558 [==============================] - 251s 451ms/step - loss: 0.1020 - accuracy: 0.9649 - val_loss: 0.4381 - val_accuracy: 0.8921\n",
      "155/155 [==============================] - 12s 79ms/step - loss: 0.4727 - accuracy: 0.8852\n",
      "155/155 [==============================] - 12s 76ms/step - loss: 0.4727 - accuracy: 0.8852\n",
      "Final accuracy on test set for Hate Content Detection: 0.8852128386497498\n",
      "Epoch 1/5\n",
      "101/101 [==============================] - 50s 426ms/step - loss: 0.1466 - accuracy: 0.9523 - val_loss: 0.0269 - val_accuracy: 0.9888\n",
      "Epoch 2/5\n",
      "101/101 [==============================] - 43s 421ms/step - loss: 0.0281 - accuracy: 0.9928 - val_loss: 0.0205 - val_accuracy: 0.9860\n",
      "Epoch 3/5\n",
      "101/101 [==============================] - 41s 410ms/step - loss: 0.0091 - accuracy: 0.9978 - val_loss: 0.0314 - val_accuracy: 0.9888\n",
      "Epoch 4/5\n",
      "101/101 [==============================] - 41s 407ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.1134 - val_accuracy: 0.9776\n",
      "Epoch 5/5\n",
      "101/101 [==============================] - 41s 407ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.0741 - val_accuracy: 0.9832\n",
      "28/28 [==============================] - 2s 77ms/step - loss: 0.0984 - accuracy: 0.9765\n",
      "28/28 [==============================] - 2s 71ms/step - loss: 0.0984 - accuracy: 0.9765\n",
      "Final accuracy on test set for Spam Detection: 0.976457417011261\n"
     ]
    }
   ],
   "source": [
    "for key in processed_data:\n",
    "    if \"Hate\" in key:\n",
    "        num_classes = 3\n",
    "        X_train, X_test, y_train, y_test = prepare_data(processed_data[key], num_classes=3)\n",
    "        model = model_architecture(num_classes)\n",
    "        train_model(model, X_train, X_test, y_train, y_test, key.split(\".\")[0])\n",
    "    else:\n",
    "        num_classes = 2\n",
    "        X_train, X_test, y_train, y_test = prepare_data(processed_data[key], num_classes=2)\n",
    "        model = model_architecture(num_classes)\n",
    "        train_model(model, X_train, X_test, y_train, y_test, key.split(\".\")[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
