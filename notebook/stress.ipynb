{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam classfication "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 12:40:20.218739: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-05 12:40:20.250113: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-05 12:40:20.506181: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-05 12:40:20.508835: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-05 12:40:22.623514: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import fasttext\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding, Bidirectional, Reshape\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = '../data/Stress Detection.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_id</th>\n",
       "      <th>sentence_range</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>syntax_fk_grade</th>\n",
       "      <th>Stress Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>8601tu</td>\n",
       "      <td>(15, 20)</td>\n",
       "      <td>He said he had not felt that way before, sugge...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.253573</td>\n",
       "      <td>-0.002742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assistance</td>\n",
       "      <td>8lbrx9</td>\n",
       "      <td>(0, 5)</td>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>0</td>\n",
       "      <td>8.828316</td>\n",
       "      <td>0.292857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>9ch1zh</td>\n",
       "      <td>(15, 20)</td>\n",
       "      <td>My mom then hit me with the newspaper and it s...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.841667</td>\n",
       "      <td>0.011894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relationships</td>\n",
       "      <td>7rorpp</td>\n",
       "      <td>[5, 10]</td>\n",
       "      <td>until i met my new boyfriend, he is amazing, h...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.104027</td>\n",
       "      <td>0.141671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>survivorsofabuse</td>\n",
       "      <td>9p2gbc</td>\n",
       "      <td>[0, 5]</td>\n",
       "      <td>October is Domestic Violence Awareness Month a...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.910952</td>\n",
       "      <td>-0.204167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subreddit post_id sentence_range  \\\n",
       "0              ptsd  8601tu       (15, 20)   \n",
       "1        assistance  8lbrx9         (0, 5)   \n",
       "2              ptsd  9ch1zh       (15, 20)   \n",
       "3     relationships  7rorpp        [5, 10]   \n",
       "4  survivorsofabuse  9p2gbc         [0, 5]   \n",
       "\n",
       "                                                text  label  syntax_fk_grade  \\\n",
       "0  He said he had not felt that way before, sugge...      1         3.253573   \n",
       "1  Hey there r/assistance, Not sure if this is th...      0         8.828316   \n",
       "2  My mom then hit me with the newspaper and it s...      1         7.841667   \n",
       "3  until i met my new boyfriend, he is amazing, h...      1         4.104027   \n",
       "4  October is Domestic Violence Awareness Month a...      1         7.910952   \n",
       "\n",
       "   Stress Level  \n",
       "0     -0.002742  \n",
       "1      0.292857  \n",
       "2      0.011894  \n",
       "3      0.141671  \n",
       "4     -0.204167  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(dataset)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing Column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['subreddit', 'post_id', 'sentence_range', 'syntax_fk_grade', 'Stress Level'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicate removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing\n",
    "- Removing Stopwords\n",
    "- Removing Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>he said he had not felt that way before  sugge...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hey there r assistance  not sure if this is th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my mom then hit me with the newspaper and it s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>until i met my new boyfriend  he is amazing  h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>october is domestic violence awareness month a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  he said he had not felt that way before  sugge...      1\n",
       "1  hey there r assistance  not sure if this is th...      0\n",
       "2  my mom then hit me with the newspaper and it s...      1\n",
       "3  until i met my new boyfriend  he is amazing  h...      1\n",
       "4  october is domestic violence awareness month a...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleanText(text):\n",
    "    text = re.sub(r'RT @\\w+: ', '', text)\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = text.lower()\n",
    "    return text    \n",
    "\n",
    "df['text'] = df['text'].apply(cleanText)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(df['text'])\n",
    "y = df['label']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 12:41:55.730784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2023-11-05 12:41:55.730921: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: n00b\n",
      "2023-11-05 12:41:55.730959: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: n00b\n",
      "2023-11-05 12:41:55.731278: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 535.129.3\n",
      "2023-11-05 12:41:55.731362: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.113.1\n",
      "2023-11-05 12:41:55.731385: E tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:312] kernel version 535.113.1 does not match DSO version 535.129.3 -- cannot find working devices in this configuration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "71/71 [==============================] - 3s 17ms/step - loss: 0.6025 - accuracy: 0.6860 - val_loss: 0.5044 - val_accuracy: 0.7717\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - 1s 10ms/step - loss: 0.3459 - accuracy: 0.8729 - val_loss: 0.4691 - val_accuracy: 0.7770\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - 1s 13ms/step - loss: 0.1647 - accuracy: 0.9535 - val_loss: 0.5329 - val_accuracy: 0.7575\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0729 - accuracy: 0.9907 - val_loss: 0.5648 - val_accuracy: 0.7646\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0321 - accuracy: 0.9956 - val_loss: 0.6283 - val_accuracy: 0.7575\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 0.0156 - accuracy: 0.9987 - val_loss: 0.6922 - val_accuracy: 0.7593\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - 1s 10ms/step - loss: 0.0117 - accuracy: 0.9987 - val_loss: 0.7072 - val_accuracy: 0.7646\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 0.0106 - accuracy: 0.9987 - val_loss: 0.7725 - val_accuracy: 0.7522\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0103 - accuracy: 0.9982 - val_loss: 0.7853 - val_accuracy: 0.7628\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0103 - accuracy: 0.9982 - val_loss: 0.8526 - val_accuracy: 0.7575\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(32, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train.toarray(), y_train, epochs=10, batch_size=32, validation_data=(X_test.toarray(), y_test))\n",
    "\n",
    "model.save('../models/stressDetection.h5')\n",
    "pickle.dump(cv, open('../models/cvstress.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
